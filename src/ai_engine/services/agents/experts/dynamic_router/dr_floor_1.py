import json
import logging
import re
from langchain_ollama import OllamaLLM
from starlette.routing import Router

from ai_engine.services.agents.state import AgentState

dr_logger = logging.getLogger('ai_engine.experts.router.router_floor_1')

class Floor1Router:
    def __init__(self):
        self.llm = OllamaLLM(
            model="sendo-dynamic_router-f1",
            format="json",
            temperature=0
        )

    def extract_json(self, text: str) -> dict:
        """
        H√†m b√≥c t√°ch JSON t·ª´ chu·ªói vƒÉn b·∫£n b·∫•t k·ª≥ c·ªßa LLM
        """
        try:
            # T√¨m n·ªôi dung n·∫±m gi·ªØa { v√† }
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                return json.loads(match.group())
            return None
        except Exception:
            return None

    async def categorize(self, state: AgentState):
        message = state["message"]
        has_file = "YES" if state.get("file_data") else "NO"

        # Input cho model
        input_text = f"Message: {message} | File: {has_file}"

        try:
            response = await self.llm.ainvoke(input_text)
            # AI Debug
            dr_logger.info(f"üîç Raw AI Response: {response}")

            data = self.extract_json(response)
            if data: return data
            raise dr_logger.error("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá trong response")
        except Exception as e:
            dr_logger.info(f"‚ùå L·ªói Router Floor 1: {str(e)}")
            return {
                "decision": "TEXT",
                "reasoning": "Fallback to text expert"
            }