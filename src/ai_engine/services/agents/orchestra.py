# src/ai_engine/services/agents/orchestra.py
import logging
from typing import Optional

from langgraph.graph import StateGraph, END

from ai_engine.services.agents.state import AgentState
from ai_engine.schemas.ai_schema import AIResponse
from ai_engine.services.agents.experts.table_expert import TableExpert
from ai_engine.services.agents.experts.dynamic_router.dr_floor_1 import Floor1Router

orchestra_logger = logging.getLogger("ai_engine.orchestra")

class Orchestra:
    def __init__(self):
        self.table_expert = TableExpert()

        self.dr_floor_1_router = Floor1Router()
        workflow = StateGraph(AgentState)

        # Äá»‹nh nghÄ©a cÃ¡c Node
        workflow.add_node("dr_floor_1", self.dr_floor_1)
        workflow.add_node("text_expert", self.process_text)
        workflow.add_node("table_expert", self.process_table)
        workflow.add_node("aggregator", self.aggregator_and_respond)

        # Cháº¡y song song text vÃ  image cÃ¹ng lÃºc!
        workflow.set_entry_point("dr_floor_1")

        # Setup Dynamic Router Floor 1
        workflow.add_conditional_edges(
            "dr_floor_1",
            self.balancer_decision,
            {
                "table_expert": "table_expert",
                "text_expert": "text_expert",
                "aggregator": "aggregator",
            }
        )

        # Äá»• context vá» Aggregator
        workflow.add_edge("text_expert", "aggregator")
        workflow.add_edge("table_expert", "aggregator")

        workflow.add_edge("aggregator", END)
        self.app = workflow.compile()
        orchestra_logger.info("ğŸ» Orchestra initialized!")

    async def dispatch(self, message: str, file_data: Optional[bytes] = None) -> AIResponse:
        """
        HÃ m khá»Ÿi Ä‘á»™ng
        1. Nháº­n input tá»« AI Service.
        2. Äáº©y vÃ o LangGraph Ä‘á»ƒ cháº¡y song song.
        3. Gom káº¿t quáº£ tráº£ vá» cho Backend.
        """
        try:
            orchestra_logger.info("--- Orchestra Starting ---")
            # 1. Khá»Ÿi táº¡o State
            inputs = {
                "message": [message],
                "file_data": file_data,
                "text_context": "",
                "file_context": ""
            }

            # 2. Thá»±c thi Graph
            result = await self.app.ainvoke(inputs)

            return AIResponse(
                diagnosis=result.get("diagnosis", "KhÃ´ng tÃ¬m tháº¥y lá»—i cá»¥ thá»ƒ."),
                case_type=result.get("case_type", "General Support"),
                solution=result.get("solution", "Vui lÃ²ng liÃªn há»‡ bá»™ pháº­n ká»¹ thuáº­t Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t."),
                response=result.get("final_answer", "Xin lá»—i, mÃ¬nh gáº·p chÃºt váº¥n Ä‘á» khi xá»­ lÃ½ yÃªu cáº§u.")
            )
        except Exception as e:
            orchestra_logger.error(f"âŒ Lá»—i nghiÃªm trá»ng táº¡i Orchestra: {str(e)}", exc_info=True)
            return AIResponse(
                diagnosis="System Crash",
                case_type="Error",
                solution="Restart Service",
                response=str(e)
            )

    async def dr_floor_1(self, state: AgentState):
        """
        Gá»i AI LOCAL Ä‘á»ƒ quyáº¿t Ä‘á»‹nh luá»“ng cháº¡y
        """
        orchestra_logger.info("ğŸ›  Router: PhÃ¢n loáº¡i dá»¯ liá»‡u...")
        # TODO: Logic lá»c loáº¡i file cÆ¡ báº£n
        result = await self.dr_floor_1_router.categorize(state)

        decision = result.get("decision", ["text_expert"])
        reasoning = result.get("reasoning", "No reasoning provided")

        orchestra_logger.info(f"ğŸ¯ AI Decision: {decision} | LÃ½ do: {reasoning}")


        return {
            "router_decision": decision,
            "thinking_log": [f"Router: KÃ­ch hoáº¡t {decision} vÃ¬ {reasoning}"]
        }

    async def balancer_decision(self, state: AgentState):
        """
        LangGraph cho phÃ©p tráº£ vá» má»™t list cÃ¡c node Ä‘á»ƒ cháº¡y song song.
        Náº¿u list rá»—ng, mÃ¬nh báº¯t nÃ³ nháº£y tá»›i aggregator luÃ´n.
        """
        decision = state.get("router_decision", [])
        if not decision:
            return "aggregator"

        valid_nodes = ["table_expert", "text_expert", "aggregator"]
        final_path = [d for d in decision if d in valid_nodes]

        return final_path if final_path else "aggregator"

    async def process_text(self, state: AgentState):
        orchestra_logger.info("ğŸ“ Calling Text Expert: Äang phÃ¢n tÃ­ch yÃªu cáº§u...")
        # TODO: PHÃ¢n tÃ­ch "Äá»‹t máº¹ lá»—i rá»“i"
        return {"text_context": "NgÆ°á»i dÃ¹ng bÃ¡o lá»—i Ä‘á»“ng bá»™ dá»¯ liá»‡u."}

    async def process_table(self, state: AgentState):
        if not state.get("file_data"):
            return {"thinking_logs": ["Expert Table: KhÃ´ng cÃ³ file, bá» qua bÆ°á»›c nÃ y."]}
        orchestra_logger.info("ğŸ“Š Calling Table Expert: Äang Ä‘á»c dá»¯ liá»‡u báº£ng...")
        result = await self.table_expert.analyze(state["file_data"])
        return result

    async def aggregator_and_respond(self, state: AgentState):
        orchestra_logger.info("ğŸ¤– Aggregator: Äang tá»•ng há»£p Context...")
        # Láº¥y text_context + file_context Ä‘á»ƒ ra cháº©n Ä‘oÃ¡n cuá»‘i
        return {
            "diagnosis": f"Lá»—i ID #123 dá»±a trÃªn: {state['text_context']}",
            "case_type": "Transaction Error",
            "solution": "Kiá»ƒm tra láº¡i gateway Senpay",
            "final_answer": "Case nÃ y do ID #123 bá»‹ treo, Ä‘á»ƒ mÃ¬nh bÃ¡o team dev fix."
        }